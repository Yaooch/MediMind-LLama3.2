import torch
from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
import numpy as np

# ================= é…ç½®åŒºåŸŸ =================
# æ‚¨çš„ SFT æ¨¡åž‹è·¯å¾„
# MODEL_PATH = "./merged-llama3-3b-sft-CMB-v1"
MODEL_PATH = "./models/LLM-Research/Llama-3___2-3B-Instruct"

# C-Eval çš„ä¸‰ä¸ªåŒ»å­¦ç§‘ç›®
TASKS = [
    "basic_medicine",    # åŸºç¡€åŒ»å­¦
    "clinical_medicine", # ä¸´åºŠåŒ»å­¦
    "physician"          # åŒ»å¸ˆèµ„æ ¼
]
# ===========================================

def load_model_and_tokenizer(model_path):
    print(f"ðŸš€ Loading model from: {model_path}")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        device_map="auto",
        torch_dtype=torch.bfloat16, # 3Bæ¨¡åž‹æŽ¨èç”¨BF16ï¼Œå¦‚æžœæŠ¥é”™æ˜¾å¡ä¸æ”¯æŒåˆ™æ”¹ä¸ºfloat16
        trust_remote_code=True
    )
    return model, tokenizer, device

def format_example(item):
    """
    å°† C-Eval çš„ä¸€è¡Œæ•°æ®æ ¼å¼åŒ–ä¸ºæ¨¡åž‹è®­ç»ƒæ—¶çš„æ ·å­
    æ ¼å¼ï¼šé¢˜ç›® + é€‰é¡¹ + ç­”æ¡ˆ
    """
    question = item['question']
    options = f"A. {item['A']}\nB. {item['B']}\nC. {item['C']}\nD. {item['D']}"
    answer = item['answer']
    
    # è¿™é‡Œæž„é€ ä¸€ä¸ªç¬¦åˆäººç±»é˜…è¯»é€»è¾‘çš„å®Œæ•´æ–‡æœ¬
    # å¦‚æžœæ‚¨çš„ SFT è®­ç»ƒæ•°æ®æœ‰ç‰¹å®šçš„ prompt æ¨¡æ¿ï¼ˆæ¯”å¦‚ ChatMLï¼‰ï¼Œè¿™é‡Œæœ€å¥½ä¿æŒä¸€è‡´
    # è¿™é‡Œä½¿ç”¨é€šç”¨çš„â€œå®Œå½¢å¡«ç©ºâ€é£Žæ ¼ï¼Œè¿™å¯¹ PPL è®¡ç®—æœ€å…¬å¹³
    text = f"é¢˜ç›®ï¼š{question}\n{options}\nç­”æ¡ˆï¼š{answer}"
    return text

def calculate_perplexity(model, tokenizer, device, dataset):
    model.eval()
    nlls = [] # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ Negative Log Likelihood
    total_tokens = 0
    
    with torch.no_grad():
        for item in tqdm(dataset, desc="Calculating PPL"):
            # 1. æ ¼å¼åŒ–æ–‡æœ¬
            text = format_example(item)
            
            # 2. ç¼–ç 
            encodings = tokenizer(text, return_tensors="pt")
            input_ids = encodings.input_ids.to(device)
            target_ids = input_ids.clone()
            
            # 3. è®¡ç®— Loss
            # HuggingFace çš„ loss é»˜è®¤æ˜¯ CrossEntropyLoss
            outputs = model(input_ids, labels=target_ids)
            
            # outputs.loss æ˜¯è¿™ä¸ªæ ·æœ¬æ‰€æœ‰ token loss çš„å¹³å‡å€¼
            # æˆ‘ä»¬éœ€è¦è¿˜åŽŸæˆ sumï¼Œå› ä¸ºä¸åŒæ ·æœ¬é•¿åº¦ä¸åŒï¼Œä¸èƒ½ç›´æŽ¥å¯¹ loss æ±‚å¹³å‡
            neg_log_likelihood = outputs.loss * input_ids.shape[1]
            
            nlls.append(neg_log_likelihood)
            total_tokens += input_ids.shape[1]

    # 4. è®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„ PPL
    # PPL = exp( Sum(Loss) / Total_Tokens )
    total_nll = torch.stack(nlls).sum()
    ppl = torch.exp(total_nll / total_tokens)
    
    return ppl.item()

def main():
    model, tokenizer, device = load_model_and_tokenizer(MODEL_PATH)
    
    results = {}
    print("\nStarting PPL Evaluation on C-Eval Medicine subsets...")
    
    for task in TASKS:
        print(f"\nðŸ§ª Evaluating task: {task}")
        try:
            # åŠ è½½éªŒè¯é›† (split='val')
            dataset = load_dataset("ceval/ceval-exam", task, split="val", trust_remote_code=True)
            
            ppl = calculate_perplexity(model, tokenizer, device, dataset)
            results[task] = ppl
            print(f"   -> {task} PPL: {ppl:.4f}")
            
        except Exception as e:
            print(f"   -> Error evaluating {task}: {e}")
            results[task] = "Error"

    print("\n" + "="*40)
    print("ðŸ“Š Final Perplexity Results")
    print("="*40)
    avg_ppl = 0
    count = 0
    for task, score in results.items():
        print(f"{task:<25}: {score:.4f}")
        if isinstance(score, (int, float)):
            avg_ppl += score
            count += 1
    
    if count > 0:
        print("-" * 40)
        print(f"Average Medical PPL    : {avg_ppl/count:.4f}")
    print("="*40)

if __name__ == "__main__":
    main()